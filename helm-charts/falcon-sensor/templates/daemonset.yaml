{{- if and .Values.node.enabled (not .Values.node.cleanupOnly) }}
{{- $imagePullSecretName := include "falcon-sensor.node.imagePullSecretName" . }}
{{- $registryConfigJson := include "falcon-sensor.node.registryConfigJson" . }}
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: {{ include "falcon-sensor.fullname" . }}
  labels:
    app: "{{ include "falcon-sensor.name" . }}"
    app.kubernetes.io/name: {{ include "falcon-sensor.name" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
    app.kubernetes.io/component: "kernel_sensor"
    crowdstrike.com/provider: crowdstrike
    helm.sh/chart: {{ include "falcon-sensor.chart" . }}
    {{- if .Values.node.daemonset.labels }}
    {{- range $key, $value := .Values.node.daemonset.labels }}
    {{ $key }}: {{ $value | quote }}
    {{- end }}
    {{- end }}
  {{- if .Values.node.daemonset.annotations }}
  annotations:
    {{- range $key, $value := .Values.node.daemonset.annotations }}
    {{ $key }}: {{ $value | quote }}
    {{- end }}
  {{- end }}
  namespace: {{ include "falcon-sensor.namespace" . }}
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "falcon-sensor.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
      app.kubernetes.io/component: "kernel_sensor"
      crowdstrike.com/provider: crowdstrike
  updateStrategy:
    type: {{ .Values.node.daemonset.updateStrategy }}
    {{- if and (eq .Values.node.daemonset.updateStrategy "RollingUpdate") (ne (int .Values.node.daemonset.maxUnavailable) 1) }}
    rollingUpdate:
      maxUnavailable: {{ .Values.node.daemonset.maxUnavailable }}
    {{- end }}
  template:
    metadata:
      annotations:
        {{ .Values.node.daemonset.podAnnotationKey }}: disabled
        {{- range $key, $value := .Values.node.podAnnotations }}
        {{ $key }}: {{ $value | quote }}
        {{- end }}
        checksum/configmap: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum | quote }}
      labels:
        app: "{{ include "falcon-sensor.name" . }}"
        app.kubernetes.io/name: {{ include "falcon-sensor.name" . }}
        app.kubernetes.io/instance: {{ .Release.Name }}
        app.kubernetes.io/managed-by: {{ .Release.Service }}
        app.kubernetes.io/component: "kernel_sensor"
        crowdstrike.com/provider: crowdstrike
        helm.sh/chart: {{ include "falcon-sensor.chart" . }}
        {{- if .Values.node.daemonset.labels }}
        {{- range $key, $value := .Values.node.daemonset.labels }}
        {{ $key }}: {{ $value | quote }}
        {{- end }}
        {{- end }}
        {{ include "falcon-sensor.workloadDeployAllowlistLabel" . }}
    spec:
    {{- if and (len $imagePullSecretName) (len $registryConfigJson) }}
      {{- fail "node.image.pullSecrets and node.image.registryConfigJSON cannot be used together." }}
    {{- else }}
    {{- if or (len $imagePullSecretName) (len $registryConfigJson) }}
      imagePullSecrets:
      {{- if (len $imagePullSecretName) }}
        - name: {{ $imagePullSecretName }}
      {{- end }}
      {{- if (len $registryConfigJson) }}
        - name: {{ include "falcon-sensor.fullname" . }}-pull-secret
      {{- end }}
    {{- end }}
    {{- end }}
    {{- if .Values.node.daemonset.tolerations }}
      tolerations:
      {{- with .Values.node.daemonset.tolerations }}
        {{- toYaml . | nindent 6 }}
      {{- end }}
    {{- end }}
      nodeSelector:
        kubernetes.io/os: linux
    {{- if .Values.node.daemonset.nodeAffinity }}
      affinity:
        nodeAffinity:
        {{- with .Values.node.daemonset.nodeAffinity }}
          {{- toYaml . | nindent 10 }}
        {{- end }}
    {{- end }}
      # We add nobody fsGroup to allow default projected service account to be readable
      # by extensibility processes (that run in a user namespace).
      # It is set as supplemental group for any process in the container.
      securityContext:
        fsGroup: 65534
      initContainers:
      # This init container creates empty falconstore file so that when
      # it's mounted into the sensor-node-container, k8s would just use it
      # rather than creating a directory.  Mounting falconstore file as
      # a file volume ensures that AID is preserved across container
      # restarts.  Sensor versions 6.54+ have a helper binary to initialize falconstore.
      - name: init-falconstore
        image: "{{ include "falcon-sensor.image" . }}"
        imagePullPolicy: "{{ .Values.node.image.pullPolicy }}"
        command:
          - /bin/bash
        {{ include "falcon-sensor.initArgs" . | nindent 8 }}
        {{- if or .Values.node.gke.autopilot .Values.node.daemonset.resources }}
        resources:
          requests:
            cpu: 10m
            ephemeral-storage: 100Mi
            memory: 50Mi
          limits:
            cpu: 10m
            ephemeral-storage: 100Mi
            memory: 50Mi
        {{- end }}
        securityContext:
          runAsUser: 0
          privileged: true
          allowPrivilegeEscalation: true
        {{- if .Values.node.gke.autopilot }}
          readOnlyRootFilesystem: true
          capabilities:
            add:
              - SYS_ADMIN
              - SYS_PTRACE
              - SYS_CHROOT
              - DAC_READ_SEARCH
        {{- else }}
          readOnlyRootFilesystem: false
        {{- end }}
        env:
          - name: POD_NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
      containers:
      - name: falcon-node-sensor
        image: "{{ include "falcon-sensor.image" . }}"
        imagePullPolicy: "{{ .Values.node.image.pullPolicy }}"
        # Various pod security context settings. Bear in mind that many of these have an impact
        # on the Falcon Sensor working correctly.
        #
        # - User that the container will execute as. Typically necessary to run as root (0).
        # - Runs the Falcon Sensor containers as privileged containers. This is required when
        #   running the Falcon Linux Sensor on Kubernetes nodes to properly run in the node's
        #   kernel and to actually protect the node.
        securityContext:
          runAsUser: 0
          privileged: true
          readOnlyRootFilesystem: false
          allowPrivilegeEscalation: true
        {{- if .Values.node.gke.autopilot }}
          capabilities:
            add:
              - SYS_ADMIN
              - SETGID
              - SETUID
              - SYS_PTRACE
              - SYS_CHROOT
              - DAC_OVERRIDE
              - SETPCAP
              - DAC_READ_SEARCH
              - BPF
              - PERFMON
              - SYS_RESOURCE
              - NET_RAW
              - CHOWN
              - NET_ADMIN
        {{- end }}
        {{- if (eq .Values.node.backend "bpf") }}
        {{- include "falcon-sensor.daemonsetResources" . | nindent 8 }}
        {{- end }}
        env:
          - name: POD_NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
        envFrom:
        - configMapRef:
            name: {{ include "falcon-sensor.configMapName" . }}
        {{- if (include "falcon-sensor.falconSecretEnabled" . | eq "true") }}
        - secretRef:
            name: {{ include "falcon-sensor.falconSecretName" . }}
        {{- end }}
        volumeMounts:
          - name: falconstore
            mountPath: /opt/CrowdStrike/falconstore
      volumes:
        - name: falconstore
          hostPath:
            path: /opt/CrowdStrike/falconstore
      serviceAccountName: {{ .Values.serviceAccount.name }}
      terminationGracePeriodSeconds: {{ .Values.node.terminationGracePeriod }}
    {{- if or .Values.node.daemonset.priorityClassName .Values.node.gke.autopilot }}
      priorityClassName: {{ include "falcon-sensor.priorityClassName" . }}
    {{- end }}
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      hostPID: true
      hostIPC: true
{{- end }}
